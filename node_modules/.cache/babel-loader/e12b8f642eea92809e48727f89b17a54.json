{"ast":null,"code":"import _classCallCheck from\"/Users/meredith/Desktop/website/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/Users/meredith/Desktop/website/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/Users/meredith/Desktop/website/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/Users/meredith/Desktop/website/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/Users/meredith/Desktop/website/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import{Link}from'react-router-dom';import tiletunesdemo from'./tile_tunes_demo.mp4';import tiletunes from'./imgs/tiletunes.png';import tiletunesdoc from'./tile_tunes_report.pdf';import tiletunesdesign from'./imgs/tiletunes-initial.png';import tiletunescardboard from'./imgs/tiletunes-cardboard.png';import tiletuneslego from'./imgs/tiletunes-lego.png';import tiletunesinitialCAD from'./imgs/tiletunes-initialCAD.png';import tiletunesprototype1 from'./imgs/tiletunes-prototype1.png';import tiletunesfinalCAD from'./imgs/tiletunes-finalCAD.png';import tiletunesteam from'./imgs/tiletunes-team.jpeg';import tiletunesschematic1 from'./imgs/tiletunes-schematic1.jpg';import tiletunesschematic2 from'./imgs/tiletunes-schematic2.png';var TileTunes=/*#__PURE__*/function(_Component){_inherits(TileTunes,_Component);function TileTunes(){_classCallCheck(this,TileTunes);return _possibleConstructorReturn(this,_getPrototypeOf(TileTunes).apply(this,arguments));}_createClass(TileTunes,[{key:\"render\",value:function render(){return React.createElement(\"div\",{className:\"App-body-project\"},React.createElement(\"h2\",null,\"Tile Tunes\"),React.createElement(\"h3\",null,\"Aug. \\u2013 Dec. 2018\"),React.createElement(\"div\",{className:\"App-body-project-video\"},React.createElement(\"video\",{className:\"video-js\",controls:true,preload:\"auto\",poster:tiletunes,\"data-setup\":'{}'},React.createElement(\"source\",{src:tiletunesdemo,type:\"video/mp4\"}),\"Your browser does not support the video tag.\")),React.createElement(\"h4\",null,\"Introduction\"),React.createElement(\"p\",null,\"We live in a world with hundreds of instruments\\u2014ways one can physically create music. Musical compositions often begin by writing down notes on a sheet of paper or computer software. This creative process, however, is noticeably more removed from the physical realm of playing the music on an instrument. In addition, music visualization is often disconnected from tangible interaction. We seek to bridge this gap between musical ideas and the tangible world through physical computing that fosters creativity.\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"Introducing Tile Tunes: a robot that moves along a user-drawn track (two black lines), reading and interpreting colored paper \\u2018tiles\\u2019 along the track as musical notes. Two IR sensors at the front of the robot follow the drawn track while a color sensor searches for and interprets the colored tiles. When a color is interpreted as a musical note, the respective note is visually displayed on an OLED screen and sent to an audio breakout board, which outputs the note\\u2019s sound through a connected speaker. Users can quickly make and modify their own musical compositions in real-time by moving colored tiles around the track.\"),React.createElement(\"h4\",null,\"Overview\"),React.createElement(\"p\",null,\"1. Related Work\",React.createElement(\"br\",null),\"2. Initial Design\",React.createElement(\"br\",null),\"3. Low-Fidelity Prototypes\",React.createElement(\"br\",null),\"4. Initial High-Fidelity Prototype\",React.createElement(\"br\",null),\"5. Final High-Fidelity Prototype\",React.createElement(\"br\",null),\"6. Reflection & Future Work\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"This project was done in collaboration with Melissa Avila and Alan Lee. I was primarily responsible for the electrical and microcontroller components of the project. My own personal goals for Tile Tunes were to gain experience working on user experience-focused projects, and learning how to approach engineering with a design-focused mindset.\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"View the full documentation\\xA0\",React.createElement(\"a\",{href:tiletunesdoc,target:\"_blank\",rel:\"noopener noreferrer\"},\"here\"),\". Our code can be also be found on\\xA0\",React.createElement(\"a\",{href:\"https://github.com/MeredithYoung-Ng/Tile-Tunes\",target:\"_blank\",rel:\"noopener noreferrer\"},\"GitHub\"),\".\"),React.createElement(\"h4\",null,\"Related Work\"),React.createElement(\"p\",null,\"Our work is primarily inspired by Yuri Suzuki\\u2019s Colour Chaser project, a vehicle that follows a freely-drawn black line track and translates non-black lines (drawn over the track) into different musical pitches [1]. In addition, other work such as Specdrums [2], EyeMusic [3] and chromesthesia [4-5] translate color to pitch. Overall, Tile Tunes focuses on the intersection of the broader research areas of physical music composition and intelligent physical systems.\"),React.createElement(\"h4\",null,\"Initial Design\"),React.createElement(\"p\",null,\"Our original idea for this project was a robot that reads colored tiles along a fixed-width expandable railed track. Each colored tile would correspond to a different musical note processed in real-time, visualized on an OLED display and played on a speaker connected to an audio breakout board.\"),React.createElement(\"div\",{className:\"App-body-tiletunes-pics\"},React.createElement(\"img\",{src:tiletunesdesign,alt:\"Initial Design\"})),React.createElement(\"p\",null,\"Ultimately, after feedback from potential users, we determined that a free-drawn track would enable the user to have more creative freedom. We then incorporated this idea into our low-fidelity prototype.\"),React.createElement(\"h4\",null,\"Low-Fidelity Prototypes\"),React.createElement(\"p\",null,\"We proceeded to build several low-fidelity prototypes with cardboard and LEGOs, as shown below. We performed simple Wizard-of-Oz testing to simulate user interactions, ensuring that our design focused on improving the tangible user experience of musical composition.\"),React.createElement(\"div\",{className:\"App-body-tiletunes-pics\"},React.createElement(\"img\",{id:\"leftimg\",src:tiletunescardboard,alt:\"Cardboard Prototype\"}),React.createElement(\"img\",{src:tiletuneslego,alt:\"LEGO Prototype\"})),React.createElement(\"h4\",null,\"Initial High-Fidelity Prototype\"),React.createElement(\"p\",null,\"Incorporating feedback from our low-fidelity prototype testing into our next iteration, we proceeded to build our first high-fidelity prototype.\"),React.createElement(\"div\",{className:\"App-body-tiletunes-pics\"},React.createElement(\"img\",{id:\"leftimg\",src:tiletunesinitialCAD,alt:\"Initial CAD\"}),React.createElement(\"img\",{src:tiletunesprototype1,alt:\"First High-Fidelity Prototype\"})),React.createElement(\"p\",null,\"Our initial CAD (above) featured a T-slotted wooden box design, with mounts for the motors at the front and the ball casters at the back. We planned to have all of our electronics mounted on the top of the box, but realized we needed additional space and incorporated a second mount.\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"As our robot moves along the track, the TCS34725 color sensor continuously reads colors from tiles along the track, sending input via I2C to the RedBear Duo microcontroller, which checks if the colors satisfy one of the predetermined HSL (Hue Saturation Lightness) ranges. The RedBear then maps each detected color to its respective note letter, and visually outputs it on the Adafruit SSD1331 OLED display via SPI. \",React.createElement(\"br\",null),React.createElement(\"br\",null),\"A second RedBear Duo microcontroller controls the motors via a simple line-tracking algorithm based on the IR sensor readings.\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"For this prototype, we drew a single-lined track with a black Sharpie, adding black lines to our colored tiles to prevent the IR sensors from misinterpreting the tiles as the track. However, having paper taped down was problematic in terms of reusability (the colored paper rips upon removal), and also restricted a user\\u2019s ability to make quick modifications to their track.\"),React.createElement(\"h4\",null,\"Final High-Fidelity Prototype\"),React.createElement(\"p\",null,\"Since our audio breakout board wasn\\u2019t supported by the RedBear, we replaced the primary RedBear Duo with an Adafruit Feather M4, which has a faster processor. Ultimately, we achieved full color, visual, and audio integration. While we initially planned to play MP3 files, we switched to MIDI and a portable speaker to achieve a crisper sound. To accommodate all of these new electronic components on our robot, we redesigned our robot with a more compact acrylic three-tiered box frame (CAD below).\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"We also redesigned our track with two black lines, facilitating easier musical tile composition. The tiles were redesigned with label paper, as it was easy to print on, stuck flat to the track, was sticky enough to be reused, and did not rip easily on removal. Now, color tiles could simply be placed in between the lines.\"),React.createElement(\"div\",{className:\"App-body-tiletunes-pics\"},React.createElement(\"img\",{id:\"leftimg\",src:tiletunesfinalCAD,alt:\"Final CAD\"}),React.createElement(\"img\",{src:tiletunes,alt:\"Final High-Fidelity Prototype\"})),React.createElement(\"h4\",null,\"Reflection & Future Work\"),React.createElement(\"p\",null,\"Overall, this project sparked my interest in HCI and physical computing. It was also an amazing experience working with Alan and Melissa\\u2014our strengths all balanced each other (Alan is a mechanical engineering major, and Melissa is an information science major). This also led to me working on CrochetMatic with Prof. Fran\\xE7ois Guimbreti\\xE8re.\"),React.createElement(\"div\",{className:\"App-body-tiletunes-pics\"},React.createElement(\"img\",{src:tiletunesteam,alt:\"Team Pic\"})),React.createElement(\"p\",null,\"Regarding future work, the next step we would take would be implementing two-chord functionality. We would need additional hardware\\u2014a microcontroller that can simultaneously run two I2C, one SPI, and one UART bus, or an alternative color sensor. A higher-quality color sensor would enable us to include more musical notes, as the TCS34725 can be inconsistent. Finally, we would also like to incorporate more user interaction methods with Tile Tunes. Enabling the users to set the instrument and octave played by the robot, upload custom sounds, and configure the mapping of colors to musical notes would all enhance the user experience.\"),React.createElement(\"h4\",null,\"References\"),React.createElement(\"p\",null,\"[1] Yuri Suzuki. 2010. Colour Chaser. Retrieved September 16, 2018 from http://yurisuzuki.com/archive/works/colour-chaser/\",React.createElement(\"br\",null),\"[2] Specdrums. 2018. Specdrums. Retrieved September 16, 2018 from https://www.specdrums.com/\",React.createElement(\"br\",null),\"[3] Sami Abbouda, Shlomi Hanassya, Shelly Levy-Tzedeka, Shachar Maidenbauma, and Amir Amedi. 2014. EyeMusic: Introducing a \\u201Cvisual\\u201D colorful experience for the blind using auditory sensory substitution. Restorative Neurology and Neuroscience 32, 247-267.\",React.createElement(\"br\",null),\"[4] Siri Carpenter. 2001. Everyday fantasia: The world of synesthesia. American Psychological Association 32, 3 (March 2001).\",React.createElement(\"br\",null),\"[5] Stephen E. Palmer. 2015. What Color Is This Song? Retrieved September 16, 2018 from http://nautil.us/issue/26/color/what-color-is-this-song\"),React.createElement(\"h4\",null,\"Schematics\"),React.createElement(\"div\",{className:\"App-body-tiletunes-pics\"},React.createElement(\"img\",{src:tiletunesschematic1,alt:\"Color Sensing Schematic\"}),React.createElement(\"img\",{src:tiletunesschematic2,alt:\"Line Tracking Schematic\"})),React.createElement(\"div\",{className:\"App-body-project-buttons\"},React.createElement(Link,{to:\"/wicshistory\"},React.createElement(\"button\",{type:\"button\"},\"\\u2039 Previous: WiCS History\")),React.createElement(Link,{to:\"/work\"},React.createElement(\"button\",{type:\"button\"},\"Back to Portfolio\")),React.createElement(Link,{to:\"/discobot\"},React.createElement(\"button\",{type:\"button\"},\"Next Up: Disco Bot \\u203A\"))));}}]);return TileTunes;}(Component);export default TileTunes;","map":{"version":3,"sources":["/Users/meredith/Desktop/website/src/TileTunes.jsx"],"names":["React","Component","Link","tiletunesdemo","tiletunes","tiletunesdoc","tiletunesdesign","tiletunescardboard","tiletuneslego","tiletunesinitialCAD","tiletunesprototype1","tiletunesfinalCAD","tiletunesteam","tiletunesschematic1","tiletunesschematic2","TileTunes"],"mappings":"wkBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,OAAQC,IAAR,KAAmB,kBAAnB,CACA,MAAOC,CAAAA,aAAP,KAA0B,uBAA1B,CACA,MAAOC,CAAAA,SAAP,KAAsB,sBAAtB,CACA,MAAOC,CAAAA,YAAP,KAAyB,yBAAzB,CACA,MAAOC,CAAAA,eAAP,KAA4B,8BAA5B,CACA,MAAOC,CAAAA,kBAAP,KAA+B,gCAA/B,CACA,MAAOC,CAAAA,aAAP,KAA0B,2BAA1B,CACA,MAAOC,CAAAA,mBAAP,KAAgC,iCAAhC,CACA,MAAOC,CAAAA,mBAAP,KAAgC,iCAAhC,CACA,MAAOC,CAAAA,iBAAP,KAA8B,+BAA9B,CACA,MAAOC,CAAAA,aAAP,KAA0B,4BAA1B,CACA,MAAOC,CAAAA,mBAAP,KAAgC,iCAAhC,CACA,MAAOC,CAAAA,mBAAP,KAAgC,iCAAhC,C,GAEMC,CAAAA,S,+QACK,CACP,MACE,4BAAK,SAAS,CAAC,kBAAf,EACE,2CADF,CAEE,sDAFF,CAGE,2BAAK,SAAS,CAAC,wBAAf,EACE,6BAAO,SAAS,CAAC,UAAjB,CAA4B,QAAQ,KAApC,CAAqC,OAAO,CAAC,MAA7C,CAAoD,MAAM,CAAEX,SAA5D,CACA,aAAY,IADZ,EAEE,8BAAQ,GAAG,CAAED,aAAb,CAA4B,IAAI,CAAC,WAAjC,EAFF,gDADF,CAHF,CAUE,6CAVF,CAWE,miBAOqD,8BAPrD,CAO2D,8BAP3D,koBAXF,CA8BE,yCA9BF,CA+BE,+CAAkB,8BAAlB,qBACmB,8BADnB,8BAE4B,8BAF5B,sCAGoC,8BAHpC,oCAIkC,8BAJlC,+BAK6B,8BAL7B,CAKmC,8BALnC,2VAWyB,8BAXzB,CAW+B,8BAX/B,mCAaE,yBAAG,IAAI,CAAEE,YAAT,CAAuB,MAAM,CAAC,QAA9B,CAAuC,GAAG,CAAC,qBAA3C,SAbF,0CAgBE,yBAAG,IAAI,CAAC,gDAAR,CACA,MAAM,CAAC,QADP,CACgB,GAAG,CAAC,qBADpB,WAhBF,KA/BF,CAoDE,6CApDF,CAqDE,wfArDF,CA8DE,+CA9DF,CA+DE,uUA/DF,CAqEE,2BAAK,SAAS,CAAC,yBAAf,EACE,2BAAK,GAAG,CAAEC,eAAV,CAA2B,GAAG,CAAC,gBAA/B,EADF,CArEF,CAwEE,2OAxEF,CA6EE,wDA7EF,CA8EE,0SA9EF,CAmFE,2BAAK,SAAS,CAAC,yBAAf,EACE,2BAAK,EAAE,CAAC,SAAR,CAAkB,GAAG,CAAEC,kBAAvB,CAA2C,GAAG,CAAC,qBAA/C,EADF,CAEE,2BAAK,GAAG,CAAEC,aAAV,CAAyB,GAAG,CAAC,gBAA7B,EAFF,CAnFF,CAuFE,gEAvFF,CAwFE,gLAxFF,CA4FE,2BAAK,SAAS,CAAC,yBAAf,EACE,2BAAK,EAAE,CAAC,SAAR,CAAkB,GAAG,CAAEC,mBAAvB,CAA4C,GAAG,CAAC,aAAhD,EADF,CAEE,2BAAK,GAAG,CAAEC,mBAAV,CAA+B,GAAG,CAAC,+BAAnC,EAFF,CA5FF,CAgGE,2TAIe,8BAJf,CAIqB,8BAJrB,oaAWgC,8BAXhC,CAWsC,8BAXtC,kIAa0D,8BAb1D,CAagE,8BAbhE,+XAhGF,CAqHE,8DArHF,CAsHE,uhBAOqC,8BAPrC,CAO2C,8BAP3C,sUAtHF,CAoIE,2BAAK,SAAS,CAAC,yBAAf,EACE,2BAAK,EAAE,CAAC,SAAR,CAAkB,GAAG,CAAEC,iBAAvB,CAA0C,GAAG,CAAC,WAA9C,EADF,CAEE,2BAAK,GAAG,CAAEP,SAAV,CAAqB,GAAG,CAAC,+BAAzB,EAFF,CApIF,CAwIE,yDAxIF,CAyIE,8XAzIF,CAgJE,2BAAK,SAAS,CAAC,yBAAf,EACE,2BAAK,GAAG,CAAEQ,aAAV,CAAyB,GAAG,CAAC,UAA7B,EADF,CAhJF,CAmJE,iqBAnJF,CA8JE,2CA9JF,CA+JE,0JACyD,8BADzD,gGAG4B,8BAH5B,4QAOqD,8BAPrD,iIASwD,8BATxD,mJA/JF,CA6KE,2CA7KF,CA8KE,2BAAK,SAAS,CAAC,yBAAf,EACE,2BAAK,GAAG,CAAEC,mBAAV,CAA+B,GAAG,CAAC,yBAAnC,EADF,CAEE,2BAAK,GAAG,CAAEC,mBAAV,CAA+B,GAAG,CAAC,yBAAnC,EAFF,CA9KF,CAkLE,2BAAK,SAAS,CAAC,0BAAf,EACE,oBAAC,IAAD,EAAM,EAAE,CAAC,cAAT,EACE,8BAAQ,IAAI,CAAC,QAAb,kCADF,CADF,CAME,oBAAC,IAAD,EAAM,EAAE,CAAC,OAAT,EACE,8BAAQ,IAAI,CAAC,QAAb,sBADF,CANF,CAWE,oBAAC,IAAD,EAAM,EAAE,CAAC,WAAT,EACE,8BAAQ,IAAI,CAAC,QAAb,8BADF,CAXF,CAlLF,CADF,CAsMD,C,uBAxMqBb,S,EA2MxB,cAAec,CAAAA,SAAf","sourcesContent":["import React, { Component } from 'react';\nimport {Link} from 'react-router-dom';\nimport tiletunesdemo from './tile_tunes_demo.mp4';\nimport tiletunes from './imgs/tiletunes.png';\nimport tiletunesdoc from './tile_tunes_report.pdf';\nimport tiletunesdesign from './imgs/tiletunes-initial.png';\nimport tiletunescardboard from './imgs/tiletunes-cardboard.png';\nimport tiletuneslego from './imgs/tiletunes-lego.png';\nimport tiletunesinitialCAD from './imgs/tiletunes-initialCAD.png';\nimport tiletunesprototype1 from './imgs/tiletunes-prototype1.png';\nimport tiletunesfinalCAD from './imgs/tiletunes-finalCAD.png';\nimport tiletunesteam from './imgs/tiletunes-team.jpeg';\nimport tiletunesschematic1 from './imgs/tiletunes-schematic1.jpg';\nimport tiletunesschematic2 from './imgs/tiletunes-schematic2.png';\n\nclass TileTunes extends Component {\n  render() {\n    return (\n      <div className=\"App-body-project\">\n        <h2>Tile Tunes</h2>\n        <h3>Aug. – Dec. 2018</h3>\n        <div className=\"App-body-project-video\">\n          <video className=\"video-js\" controls preload=\"auto\" poster={tiletunes}\n          data-setup={'{}'}>\n            <source src={tiletunesdemo} type=\"video/mp4\" />\n            Your browser does not support the video tag.\n          </video>\n        </div>\n        <h4>Introduction</h4>\n        <p>We live in a world with hundreds of instruments—ways one can\n          physically create music. Musical compositions often begin by writing\n          down notes on a sheet of paper or computer software. This creative\n          process, however, is noticeably more removed from the physical realm\n          of playing the music on an instrument. In addition, music\n          visualization is often disconnected from tangible interaction. We\n          seek to bridge this gap between musical ideas and the tangible world\n          through physical computing that fosters creativity.<br /><br />\n          Introducing Tile Tunes: a robot that moves along a user-drawn track\n          (two black lines), reading and interpreting colored paper ‘tiles’\n          along the track as musical notes. Two IR sensors at the front of the\n          robot follow the drawn track while a color sensor searches for and\n          interprets the colored tiles. When a color is interpreted as a\n          musical note, the respective note is visually displayed on an OLED\n          screen and sent to an audio breakout board, which outputs the note’s\n          sound through a connected speaker. Users can quickly make and modify\n          their own musical compositions in real-time by moving colored tiles\n          around the track.\n        </p>\n        <h4>Overview</h4>\n        <p>1. Related Work<br />\n          2. Initial Design<br />\n          3. Low-Fidelity Prototypes<br />\n          4. Initial High-Fidelity Prototype<br />\n          5. Final High-Fidelity Prototype<br />\n          6. Reflection & Future Work<br /><br />\n          This project was done in collaboration with Melissa Avila and Alan\n          Lee. I was primarily responsible for the electrical and\n          microcontroller components of the project. My own personal goals for\n          Tile Tunes were to gain experience working on user experience-focused\n          projects, and learning how to approach engineering with a\n          design-focused mindset.<br /><br />\n          View the full documentation&nbsp;\n          <a href={tiletunesdoc} target=\"_blank\" rel=\"noopener noreferrer\">\n            here\n          </a>. Our code can be also be found on&nbsp;\n          <a href=\"https://github.com/MeredithYoung-Ng/Tile-Tunes\"\n          target=\"_blank\" rel=\"noopener noreferrer\">\n            GitHub\n          </a>.\n        </p>\n        <h4>Related Work</h4>\n        <p>Our work is primarily inspired by Yuri Suzuki’s Colour Chaser\n          project, a vehicle that follows a freely-drawn black line track and\n          translates non-black lines (drawn over the track) into different\n          musical pitches [1]. In addition, other work such as Specdrums [2],\n          EyeMusic [3] and chromesthesia [4-5] translate color to pitch.\n          Overall, Tile Tunes focuses on the intersection of the broader\n          research areas of physical music composition and intelligent physical\n          systems.\n        </p>\n        <h4>Initial Design</h4>\n        <p>Our original idea for this project was a robot that reads colored\n          tiles along a fixed-width expandable railed track. Each colored tile\n          would correspond to a different musical note processed in real-time,\n          visualized on an OLED display and played on a speaker connected to an\n          audio breakout board.\n        </p>\n        <div className=\"App-body-tiletunes-pics\">\n          <img src={tiletunesdesign} alt=\"Initial Design\"/>\n        </div>\n        <p>Ultimately, after feedback from potential users, we determined that\n          a free-drawn track would enable the user to have more creative\n          freedom. We then incorporated this idea into our low-fidelity\n          prototype.\n        </p>\n        <h4>Low-Fidelity Prototypes</h4>\n        <p>We proceeded to build several low-fidelity prototypes with cardboard\n          and LEGOs, as shown below. We performed simple Wizard-of-Oz testing to\n          simulate user interactions, ensuring that our design focused on\n          improving the tangible user experience of musical composition.\n        </p>\n        <div className=\"App-body-tiletunes-pics\">\n          <img id=\"leftimg\" src={tiletunescardboard} alt=\"Cardboard Prototype\"/>\n          <img src={tiletuneslego} alt=\"LEGO Prototype\"/>\n        </div>\n        <h4>Initial High-Fidelity Prototype</h4>\n        <p>Incorporating feedback from our low-fidelity prototype testing into\n          our next iteration, we proceeded to build our first high-fidelity\n          prototype.\n        </p>\n        <div className=\"App-body-tiletunes-pics\">\n          <img id=\"leftimg\" src={tiletunesinitialCAD} alt=\"Initial CAD\"/>\n          <img src={tiletunesprototype1} alt=\"First High-Fidelity Prototype\"/>\n        </div>\n        <p>Our initial CAD (above) featured a T-slotted wooden box design,\n          with mounts for the motors at the front and the ball casters at the\n          back. We planned to have all of our electronics mounted on the top of\n          the box, but realized we needed additional space and incorporated a\n          second mount.<br /><br />\n          As our robot moves along the track, the TCS34725 color sensor\n          continuously reads colors from tiles along the track, sending input\n          via I2C to the RedBear Duo microcontroller, which checks if the\n          colors satisfy one of the predetermined HSL (Hue Saturation\n          Lightness) ranges. The RedBear then maps each detected color to\n          its respective note letter, and visually outputs it on the Adafruit\n          SSD1331 OLED display via SPI. <br /><br />\n          A second RedBear Duo microcontroller controls the motors via a simple\n          line-tracking algorithm based on the IR sensor readings.<br /><br />\n          For this prototype, we drew a single-lined track with a black\n          Sharpie, adding black lines to our colored tiles to prevent the IR\n          sensors from misinterpreting the tiles as the track. However, having\n          paper taped down was problematic in terms of reusability (the colored\n          paper rips upon removal), and also restricted a user’s ability to\n          make quick modifications to their track.\n        </p>\n        <h4>Final High-Fidelity Prototype</h4>\n        <p>Since our audio breakout board wasn’t supported by the RedBear, we\n          replaced the primary RedBear Duo with an Adafruit Feather M4, which\n          has a faster processor. Ultimately, we achieved full color, visual,\n          and audio integration. While we initially planned to play MP3 files,\n          we switched to MIDI and a portable speaker to achieve a crisper\n          sound. To accommodate all of these new electronic components on our\n          robot, we redesigned our robot with a more compact acrylic\n          three-tiered box frame (CAD below).<br /><br />\n          We also redesigned our track with two black lines, facilitating\n          easier musical tile composition. The tiles were redesigned with label\n          paper, as it was easy to print on, stuck flat to the track, was\n          sticky enough to be reused, and did not rip easily on removal. Now,\n          color tiles could simply be placed in between the lines.\n        </p>\n        <div className=\"App-body-tiletunes-pics\">\n          <img id=\"leftimg\" src={tiletunesfinalCAD} alt=\"Final CAD\"/>\n          <img src={tiletunes} alt=\"Final High-Fidelity Prototype\"/>\n        </div>\n        <h4>Reflection & Future Work</h4>\n        <p>Overall, this project sparked my interest in HCI and physical\n          computing. It was also an amazing experience working with Alan and\n          Melissa—our strengths all balanced each other (Alan is a mechanical\n          engineering major, and Melissa is an information science major). This\n          also led to me working on CrochetMatic with Prof. François\n          Guimbretière.\n        </p>\n        <div className=\"App-body-tiletunes-pics\">\n          <img src={tiletunesteam} alt=\"Team Pic\"/>\n        </div>\n        <p>Regarding future work, the next step we would take would be\n          implementing two-chord functionality. We would need additional\n          hardware—a microcontroller that can simultaneously run two I2C, one\n          SPI, and one UART bus, or an alternative color sensor. A\n          higher-quality color sensor would enable us to include more musical\n          notes, as the TCS34725 can be inconsistent. Finally, we would also\n          like to incorporate more user interaction methods with Tile Tunes.\n          Enabling the users to set the instrument and octave played by the\n          robot, upload custom sounds, and configure the mapping of colors to\n          musical notes would all enhance the user experience.\n        </p>\n        <h4>References</h4>\n        <p>[1] Yuri Suzuki. 2010. Colour Chaser. Retrieved September 16, 2018\n          from http://yurisuzuki.com/archive/works/colour-chaser/<br />\n          [2] Specdrums. 2018. Specdrums. Retrieved September 16, 2018 from\n          https://www.specdrums.com/<br />\n          [3]\tSami Abbouda, Shlomi Hanassya, Shelly Levy-Tzedeka, Shachar\n          Maidenbauma, and Amir Amedi. 2014. EyeMusic: Introducing a “visual”\n          colorful experience for the blind using auditory sensory substitution.\n          Restorative Neurology and Neuroscience 32, 247-267.<br />\n          [4]\tSiri Carpenter. 2001. Everyday fantasia: The world of synesthesia.\n          American Psychological Association 32, 3 (March 2001).<br />\n          [5]\tStephen E. Palmer. 2015. What Color Is This Song? Retrieved\n          September 16, 2018 from\n          http://nautil.us/issue/26/color/what-color-is-this-song\n        </p>\n        <h4>Schematics</h4>\n        <div className=\"App-body-tiletunes-pics\">\n          <img src={tiletunesschematic1} alt=\"Color Sensing Schematic\"/>\n          <img src={tiletunesschematic2} alt=\"Line Tracking Schematic\"/>\n        </div>\n        <div className=\"App-body-project-buttons\">\n          <Link to=\"/wicshistory\">\n            <button type=\"button\">\n              &#8249; Previous: WiCS History\n            </button>\n          </Link>\n          <Link to=\"/work\">\n            <button type=\"button\">\n              Back to Portfolio\n            </button>\n          </Link>\n          <Link to=\"/discobot\">\n            <button type=\"button\">\n              Next Up: Disco Bot &#8250;\n            </button>\n          </Link>\n        </div>\n      </div>\n    );\n  }\n}\n\nexport default TileTunes;\n"]},"metadata":{},"sourceType":"module"}